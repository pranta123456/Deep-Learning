{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\n","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:04:13.896227Z","iopub.execute_input":"2022-07-18T21:04:13.897325Z","iopub.status.idle":"2022-07-18T21:04:13.902925Z","shell.execute_reply.started":"2022-07-18T21:04:13.897273Z","shell.execute_reply":"2022-07-18T21:04:13.901691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = torchvision.datasets.MNIST(root = \"./data\", \n                                          train =True,\n                                          transform = transforms.ToTensor(),\n                                          download = True)\n\ntest_dataset = torchvision.datasets.MNIST(root = \"./data\", \n                                          train = False,\n                                          transform = transforms.ToTensor())","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:04:20.276060Z","iopub.execute_input":"2022-07-18T21:04:20.276474Z","iopub.status.idle":"2022-07-18T21:04:20.366536Z","shell.execute_reply.started":"2022-07-18T21:04:20.276442Z","shell.execute_reply":"2022-07-18T21:04:20.365452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 100","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:04:23.578851Z","iopub.execute_input":"2022-07-18T21:04:23.579222Z","iopub.status.idle":"2022-07-18T21:04:23.583854Z","shell.execute_reply.started":"2022-07-18T21:04:23.579192Z","shell.execute_reply":"2022-07-18T21:04:23.582855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                          batch_size = batch_size,\n                                          shuffle = True)\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n                                          batch_size = batch_size,\n                                          shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:04:27.048186Z","iopub.execute_input":"2022-07-18T21:04:27.048616Z","iopub.status.idle":"2022-07-18T21:04:27.057549Z","shell.execute_reply.started":"2022-07-18T21:04:27.048582Z","shell.execute_reply":"2022-07-18T21:04:27.056414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:04:30.601700Z","iopub.execute_input":"2022-07-18T21:04:30.602111Z","iopub.status.idle":"2022-07-18T21:04:30.607569Z","shell.execute_reply.started":"2022-07-18T21:04:30.602078Z","shell.execute_reply":"2022-07-18T21:04:30.606419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n        super(RNN, self).__init__()\n        \n        self.hidden_dim = hidden_dim\n        self.layer_dim = layer_dim\n        \n#         self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first = True, nonlinearity = \"relu\")\n#         self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first = True)\n        self.gru = nn.GRU(input_dim, hidden_dim, layer_dim, batch_first= True)\n        \n#         for name, param in self.gru.named_parameters():\n#             if \"bias\" in name:\n#                 nn.init.constant_(param, 0.0)\n#             elif \"weight_ih\" in name:\n#                 nn.init.kaiming_normal_(param)\n#             elif \"weight_hh\" in name:\n#                 nn.init.kaiming_normal_(param)\n        \n        self.fc = nn.Linear(hidden_dim, output_dim)\n        \n    def forward(self, x):\n        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)\n#         c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)\n        out, hn = self.gru(x, h0)\n#         out, hn = self.lstm(x, (h0,c0))\n        \n        out = self.fc(out[:,-1,:])\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:55:44.818157Z","iopub.execute_input":"2022-07-18T21:55:44.818724Z","iopub.status.idle":"2022-07-18T21:55:44.831219Z","shell.execute_reply.started":"2022-07-18T21:55:44.818682Z","shell.execute_reply":"2022-07-18T21:55:44.829497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dim = 28\nhidden_dim = 128\nlayer_dim = 1\noutput_dim = 10\nseq_len = 28","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:55:50.483259Z","iopub.execute_input":"2022-07-18T21:55:50.483655Z","iopub.status.idle":"2022-07-18T21:55:50.490446Z","shell.execute_reply.started":"2022-07-18T21:55:50.483623Z","shell.execute_reply":"2022-07-18T21:55:50.488833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RNN(input_dim, hidden_dim, layer_dim, output_dim).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:55:53.723104Z","iopub.execute_input":"2022-07-18T21:55:53.723487Z","iopub.status.idle":"2022-07-18T21:55:53.732619Z","shell.execute_reply.started":"2022-07-18T21:55:53.723458Z","shell.execute_reply":"2022-07-18T21:55:53.731423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001)","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:56:00.367194Z","iopub.execute_input":"2022-07-18T21:56:00.367663Z","iopub.status.idle":"2022-07-18T21:56:00.376037Z","shell.execute_reply.started":"2022-07-18T21:56:00.367628Z","shell.execute_reply":"2022-07-18T21:56:00.374140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_steps = len(train_loader)\nnum_epochs = 5\n\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.reshape(-1, seq_len, input_dim).to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        l = loss(outputs, labels)\n        \n        l.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        if (i+1) % 100 == 0:\n            print(f\" Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss {l.item():.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:56:04.935162Z","iopub.execute_input":"2022-07-18T21:56:04.935903Z","iopub.status.idle":"2022-07-18T21:58:17.414108Z","shell.execute_reply.started":"2022-07-18T21:56:04.935762Z","shell.execute_reply":"2022-07-18T21:58:17.413198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_samples =0\nn_correct =0\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.reshape(-1, seq_len, input_dim).to(device)\n        labels = labels.to(device)\n        \n        outputs = model(images)\n        _,predicted = torch.max(outputs.data, 1)\n        n_samples += labels.size(0)\n        n_correct += (predicted == labels).sum().item()\n    \n    print(f\"Accuracy : {(n_correct/n_samples)*100} %\")","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:58:23.707582Z","iopub.execute_input":"2022-07-18T21:58:23.708002Z","iopub.status.idle":"2022-07-18T21:58:25.979723Z","shell.execute_reply.started":"2022-07-18T21:58:23.707969Z","shell.execute_reply":"2022-07-18T21:58:25.978830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-07-18T21:51:19.232645Z","iopub.execute_input":"2022-07-18T21:51:19.233076Z","iopub.status.idle":"2022-07-18T21:51:19.238935Z","shell.execute_reply.started":"2022-07-18T21:51:19.233039Z","shell.execute_reply":"2022-07-18T21:51:19.238130Z"},"trusted":true},"execution_count":null,"outputs":[]}]}